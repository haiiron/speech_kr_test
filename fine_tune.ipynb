{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! pip install pytorch-lightning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71bc7d921907d270"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torchaudio\n",
    "from glob import glob\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor, TrainingArguments, Trainer, AdamW, get_scheduler"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-27T04:21:10.112839Z",
     "start_time": "2025-03-27T04:21:10.107379Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# ----- Params -----\n",
    "\n",
    "data_dir = \"datasets/OldPeople_Voice/label/\"\n",
    "audio_dir = \"datasets/OldPeople_Voice/\"\n",
    "save_dir = \"whisper_finetuned\"\n",
    "\n",
    "# ----- ------ -----"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-27T04:30:43.050270Z",
     "start_time": "2025-03-27T04:30:43.030196Z"
    }
   },
   "id": "8fe0e23fa401af65"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class CustomAudioDataset(Dataset):\n",
    "    def __init__(self, json_list, processor):\n",
    "        self.processor = processor\n",
    "        self.data = []\n",
    "\n",
    "        # ëª¨ë“  JSON íŒŒì¼ì„ ë¦¬ìŠ¤íŠ¸ë¡œ\n",
    "        for json_path in json_list:\n",
    "            with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ\n",
    "            audio_file = os.path.join(audio_dir, data[\"ë°œí™”ì •ë³´\"][\"fileNm\"])\n",
    "            \n",
    "            # íŒŒì¼ì´ ì‹¤ì œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (ì˜¤ë¥˜ ë°©ì§€)\n",
    "            if not os.path.exists(audio_file):\n",
    "                print(f\"âš ï¸ Warning: {audio_file} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "                continue  # í•´ë‹¹ íŒŒì¼ ê±´ë„ˆë›°ê¸°\n",
    "            \n",
    "            text = data[\"ë°œí™”ì •ë³´\"][\"stt\"]\n",
    "            self.data.append((audio_file, text))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_file, text = self.data[idx]\n",
    "\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "\n",
    "        # 16kHz ìƒ˜í”Œë§ for Whisper\n",
    "        if sample_rate != 16000:\n",
    "            waveform = torchaudio.transforms.Resample(sample_rate, 16000)(waveform)\n",
    "\n",
    "        # ì˜¤ë””ì˜¤ ë°ì´í„° ë³€í™˜\n",
    "        input_features = self.processor(\n",
    "            waveform.squeeze(0).numpy(),\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "\n",
    "        # í…ìŠ¤íŠ¸ í† í°í™” í•˜ê¸°\n",
    "        labels = self.processor.tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        return {\n",
    "            \"input_features\": input_features.squeeze(0),\n",
    "            \"labels\": labels.squeeze(0)\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-27T04:17:46.776708Z",
     "start_time": "2025-03-27T04:17:46.751199Z"
    }
   },
   "id": "bf2efaeef5ad26af"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def load_data(json_path):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    audio_file = os.path.join(audio_dir, data[\"ë°œí™”ì •ë³´\"][\"fileNm\"])\n",
    "    text = data[\"ë°œí™”ì •ë³´\"][\"stt\"]\n",
    "    # duration = float(str(data[\"ë°œí™”ì •ë³´\"][\"recrdTime\"]))\n",
    "\n",
    "    return {\n",
    "        \"audio\": audio_file,  # íŒŒì¼ ê²½ë¡œ ì €ì¥\n",
    "        \"text\": text,\n",
    "        # \"duration\": duration\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-27T04:17:47.678863Z",
     "start_time": "2025-03-27T04:17:47.674121Z"
    }
   },
   "id": "ee9aa5a117860435"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "learning_rate = 1e-5\n",
    "num_epochs = 3\n",
    "gradient_accumulation_steps = 2\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-27T04:29:35.117156Z",
     "start_time": "2025-03-27T04:29:35.071048Z"
    }
   },
   "id": "97b3e65d9e001913"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d066a3185eb47a783b3e89f92bad702"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "pytorch_model.bin:   0%|          | 0.00/967M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7a44088ef65497a91083024ee8a2407"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data path : ['datasets/OldPeople_Voice/label/á„‚á…©á„‹á…µá†«á„‚á…¡á†·á„‹á…§_á„‚á…©á„‹á…µá†«á„ƒá…¢á„’á…ª77_F_á„€á…µá†·XX_62_á„Œá…¦á„Œá…®_á„‰á…µá†¯á„‚á…¢_84050.json', 'datasets/OldPeople_Voice/label/á„‚á…©á„‹á…µá†«á„‚á…¡á†·á„‹á…§_á„‚á…©á„‹á…µá†«á„ƒá…¢á„’á…ª77_F_á„€á…µá†·XX_62_á„Œá…¦á„Œá…®_á„‰á…µá†¯á„‚á…¢_84051.json', 'datasets/OldPeople_Voice/label/á„‚á…©á„‹á…µá†«á„‚á…¡á†·á„‹á…§_á„‚á…©á„‹á…µá†«á„ƒá…¢á„’á…ª77_F_á„€á…µá†·XX_62_á„Œá…¦á„Œá…®_á„‰á…µá†¯á„‚á…¢_84052.json', 'datasets/OldPeople_Voice/label/á„‚á…©á„‹á…µá†«á„‚á…¡á†·á„‹á…§_á„‚á…©á„‹á…µá†«á„ƒá…¢á„’á…ª77_F_á„€á…µá†·XX_62_á„Œá…¦á„Œá…®_á„‰á…µá†¯á„‚á…¢_84053.json', 'datasets/OldPeople_Voice/label/á„‚á…©á„‹á…µá†«á„‚á…¡á†·á„‹á…§_á„‚á…©á„‹á…µá†«á„ƒá…¢á„’á…ª77_F_á„€á…µá†·XX_62_á„Œá…¦á„Œá…®_á„‰á…µá†¯á„‚á…¢_84054.json']\n",
      "5ê°œ ë¡œë“œ.\n"
     ]
    }
   ],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained(\"SungBeom/whisper-small-ko\")\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "json_list = glob(data_dir+\"/*.json\")\n",
    "print(\"data path :\",json_list)\n",
    "dataset = CustomAudioDataset(json_list, processor)\n",
    "print(f\"{len(dataset)}ê°œ ë¡œë“œ.\")\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-27T06:51:21.632368Z",
     "start_time": "2025-03-27T06:49:28.405697Z"
    }
   },
   "id": "7ca657b529865494"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# optimizer & scheduler \n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * num_epochs\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-27T06:51:24.338843Z",
     "start_time": "2025-03-27T06:51:24.233126Z"
    }
   },
   "id": "252abca12ecef155"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Epoch [1/3], Loss: 4.7223\n",
      "ğŸš€ Epoch [2/3], Loss: 4.1509\n",
      "ğŸš€ Epoch [3/3], Loss: 3.7681\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # ë°°ì¹˜ì—ì„œ input_featuresì™€ labels ì¶”ì¶œ\n",
    "        input_features = [item[\"input_features\"].to(device) for item in batch]\n",
    "        labels = [item[\"labels\"].to(device) for item in batch]\n",
    "\n",
    "        # padding ì²˜ë¦¬\n",
    "        input_features = torch.nn.utils.rnn.pad_sequence(input_features, batch_first=True, padding_value=0)\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "\n",
    "        # ëª¨ë¸ì— ì…ë ¥\n",
    "        outputs = model(input_features, labels=labels)\n",
    "        loss = outputs.loss / gradient_accumulation_steps  # gradient accumulation ì ìš©\n",
    "        loss.backward()\n",
    "\n",
    "        if (step + 1) % gradient_accumulation_steps == 0 or (step + 1 == len(train_dataloader)):\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"ğŸš€ Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # ëª¨ë¸ ì €ì¥\n",
    "    model.save_pretrained(f\"{save_dir}/epoch_{epoch+1}\")\n",
    "    processor.save_pretrained(f\"{save_dir}/epoch_{epoch+1}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-27T06:56:17.038782Z",
     "start_time": "2025-03-27T06:52:04.725178Z"
    }
   },
   "id": "30f84c857290e6fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cb2850a0f1afc49b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TEST"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b06d938581bc1970"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ˆì¸¡ëœ í…ìŠ¤íŠ¸: ì–´ í° ë‚˜ë“¤ë§Œ ì¢‹ì•„í•˜ëŠ” ê²ƒ ê°™ì•„\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "\n",
    "model_path = \"whisper_finetuned/epoch_1\"  # XëŠ” ì €ì¥í•œ ì—í¬í¬ ë²ˆí˜¸\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_path)\n",
    "processor = WhisperProcessor.from_pretrained(model_path)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ íŒŒì¼\n",
    "audio_file = audio_dir + \"ë…¸ì¸ë‚¨ì—¬_ë…¸ì¸ëŒ€í™”77_F_ê¹€XX_62_ì œì£¼_ì‹¤ë‚´_84051.WAV\"\n",
    "\n",
    "# ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ\n",
    "waveform, sample_rate = torchaudio.load(audio_file)\n",
    "\n",
    "# WhisperëŠ” 16kHz ìƒ˜í”Œë§ ì†ë„ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ë³€í™˜ í•„ìš”\n",
    "if sample_rate != 16000:\n",
    "    waveform = torchaudio.transforms.Resample(sample_rate, 16000)(waveform)\n",
    "\n",
    "# ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ë³€í™˜\n",
    "input_features = processor(waveform.squeeze(0).numpy(), sampling_rate=16000, return_tensors=\"pt\").input_features\n",
    "input_features = input_features.to(device)\n",
    "\n",
    "# ëª¨ë¸ì„ í†µí•´ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "with torch.no_grad():\n",
    "    predicted_ids = model.generate(input_features)\n",
    "\n",
    "# ì˜ˆì¸¡ëœ í…ìŠ¤íŠ¸ ë””ì½”ë”©\n",
    "transcribed_text = processor.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"ì˜ˆì¸¡ëœ í…ìŠ¤íŠ¸:\", transcribed_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-27T06:57:18.915038Z",
     "start_time": "2025-03-27T06:57:11.659954Z"
    }
   },
   "id": "c049e24048e1b03c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
